Neurons Per Layer: [11, 10, 9, 8, 3]
Layer (0)
Weights:
0   0     0             -1.007231
0   0     1             -0.667262
0   0     2             -0.306524
0   0     3              0.247031
0   0     4             -0.436975
0   0     5             -0.257978
0   0     6             -0.004119
0   0     7             -0.161937
0   0     8             -0.190548
0   0     9             -0.839008
0   1     0              0.596330
0   1     1              0.546215
0   1     2             -0.582838
0   1     3             -0.265888
0   1     4              0.700953
0   1     5              0.922648
0   1     6             -0.195156
0   1     7             -0.043450
0   1     8             -1.498656
0   1     9             -0.416891
0   2     0              0.394564
0   2     1              0.144085
0   2     2             -0.808652
0   2     3              0.035646
0   2     4              0.564777
0   2     5              0.628734
0   2     6             -0.237833
0   2     7             -0.218068
0   2     8             -0.831995
0   2     9             -0.449855
0   3     0              0.193044
0   3     1              0.522864
0   3     2              0.621735
0   3     3             -0.274112
0   3     4              0.292179
0   3     5             -0.336820
0   3     6              0.042668
0   3     7             -0.033227
0   3     8              0.295348
0   3     9              0.350431
0   4     0             -0.178342
0   4     1              0.105220
0   4     2              1.865984
0   4     3             -0.039606
0   4     4              0.012694
0   4     5             -1.136682
0   4     6              0.079295
0   4     7             -0.043446
0   4     8              1.379191
0   4     9              1.376510
0   5     0             -0.268448
0   5     1              0.058623
0   5     2              1.629103
0   5     3             -0.154723
0   5     4             -0.583224
0   5     5             -1.488901
0   5     6             -0.124357
0   5     7             -0.090076
0   5     8              2.013508
0   5     9              1.362133
0   6     0              0.023928
0   6     1              0.429023
0   6     2             -0.354168
0   6     3             -0.019641
0   6     4             -0.339596
0   6     5             -0.662457
0   6     6              0.032124
0   6     7              0.107169
0   6     8              0.507151
0   6     9              0.944222
0   7     0             -0.318189
0   7     1              0.650378
0   7     2             -1.360276
0   7     3              0.232040
0   7     4             -0.915794
0   7     5             -0.191631
0   7     6              0.140548
0   7     7             -0.186483
0   7     8             -0.185168
0   7     9              0.468080
0   8     0             -0.482720
0   8     1              0.461539
0   8     2             -1.785953
0   8     3              0.039476
0   8     4             -0.551548
0   8     5             -0.402634
0   8     6              0.233902
0   8     7              0.223687
0   8     8             -0.600909
0   8     9              0.369974
0   9     0             -0.129223
0   9     1              0.514374
0   9     2             -1.763328
0   9     3             -0.248295
0   9     4             -0.882288
0   9     5             -0.218607
0   9     6              0.070411
0   9     7              0.110807
0   9     8             -0.948117
0   9     9              0.017553
0   10    0             -0.162298
0   10    1              0.683705
0   10    2             -1.775419
0   10    3              0.090550
0   10    4             -0.964332
0   10    5              0.134795
0   10    6             -0.270128
0   10    7              0.106652
0   10    8             -0.746764
0   10    9              0.365564

Biases:
0   0         -0.067046
0   1         -0.345705
0   2          0.769758
0   3         -0.293786
0   4          0.435496
0   5          0.810628
0   6          0.055137
0   7         -0.129960
0   8          0.354184
0   9         -0.323984

Layer (1)
Weights:
1   0     0             -0.590683
1   0     1             -0.163669
1   0     2              0.189145
1   0     3             -0.046857
1   0     4              0.023344
1   0     5             -0.344807
1   0     6             -0.221393
1   0     7              0.128562
1   0     8             -0.306746
1   1     0             -0.364252
1   1     1             -0.227718
1   1     2             -0.128247
1   1     3             -0.649573
1   1     4              0.611447
1   1     5             -0.428354
1   1     6             -0.132071
1   1     7             -0.092861
1   1     8              0.231695
1   2     0             -0.441380
1   2     1             -0.027071
1   2     2             -0.206572
1   2     3              0.641660
1   2     4             -0.576180
1   2     5              0.426288
1   2     6             -0.325292
1   2     7              1.307755
1   2     8             -0.237860
1   3     0              0.045462
1   3     1              0.173860
1   3     2              0.290253
1   3     3             -0.068779
1   3     4             -0.124215
1   3     5             -0.221591
1   3     6              0.115728
1   3     7             -0.129365
1   3     8              0.279185
1   4     0             -0.287268
1   4     1             -0.238887
1   4     2              0.278614
1   4     3              0.403390
1   4     4             -0.353611
1   4     5             -0.625078
1   4     6             -0.109771
1   4     7              0.302059
1   4     8             -0.052941
1   5     0              0.107900
1   5     1             -0.266331
1   5     2              0.818064
1   5     3              0.329129
1   5     4             -0.453830
1   5     5             -0.403881
1   5     6              0.004608
1   5     7             -0.479943
1   5     8             -0.032392
1   6     0              0.097620
1   6     1              0.027386
1   6     2             -0.197374
1   6     3              0.179162
1   6     4              0.017435
1   6     5             -0.260146
1   6     6             -0.029093
1   6     7              0.237908
1   6     8             -0.305912
1   7     0              0.191201
1   7     1              0.268643
1   7     2              0.030329
1   7     3              0.104028
1   7     4             -0.143579
1   7     5             -0.087671
1   7     6              0.244716
1   7     7              0.071418
1   7     8             -0.141994
1   8     0             -0.321058
1   8     1             -0.279470
1   8     2             -0.793216
1   8     3              0.092476
1   8     4             -0.008504
1   8     5              0.700922
1   8     6              0.206078
1   8     7              0.945445
1   8     8             -0.239601
1   9     0             -0.405442
1   9     1              0.221023
1   9     2             -0.257459
1   9     3             -0.625436
1   9     4              0.539032
1   9     5              0.327635
1   9     6              0.222324
1   9     7              0.410340
1   9     8              0.235816

Biases:
1   0          1.318581
1   1         -0.135388
1   2          0.241489
1   3          0.147541
1   4         -0.118994
1   5          0.513914
1   6          0.078607
1   7         -0.140173
1   8         -0.251169

Layer (2)
Weights:
2   0     0             -0.449689
2   0     1              0.070464
2   0     2              0.110503
2   0     3             -0.818010
2   0     4              0.299368
2   0     5             -0.237253
2   0     6             -0.114131
2   0     7              0.290579
2   1     0              0.236360
2   1     1             -0.261024
2   1     2              0.228465
2   1     3             -0.052084
2   1     4             -0.200821
2   1     5             -0.248051
2   1     6              0.028304
2   1     7             -0.187183
2   2     0             -0.032203
2   2     1             -0.016316
2   2     2              0.136510
2   2     3              0.030620
2   2     4             -0.441169
2   2     5              0.728194
2   2     6             -0.180903
2   2     7             -0.071426
2   3     0              0.557253
2   3     1             -0.048057
2   3     2             -0.230052
2   3     3             -0.269916
2   3     4             -0.140713
2   3     5              0.321911
2   3     6              0.199066
2   3     7             -0.663896
2   4     0             -0.525683
2   4     1             -0.323186
2   4     2             -0.332493
2   4     3              0.230842
2   4     4              0.437350
2   4     5             -0.203545
2   4     6             -0.119873
2   4     7              0.347657
2   5     0              0.146600
2   5     1             -0.220707
2   5     2              0.233047
2   5     3             -0.173557
2   5     4              0.769524
2   5     5             -0.478314
2   5     6              0.085399
2   5     7             -0.314914
2   6     0              0.221491
2   6     1              0.123158
2   6     2             -0.045335
2   6     3             -0.088188
2   6     4              0.324330
2   6     5             -0.068021
2   6     6             -0.266165
2   6     7              0.050312
2   7     0              0.593087
2   7     1              0.067404
2   7     2             -0.165046
2   7     3              0.172810
2   7     4              0.291401
2   7     5             -0.450479
2   7     6             -0.082591
2   7     7             -0.798543
2   8     0             -0.021011
2   8     1              0.188421
2   8     2             -0.241740
2   8     3              0.214219
2   8     4             -0.274978
2   8     5             -0.135345
2   8     6              0.113534
2   8     7              0.168686

Biases:
2   0         -0.296620
2   1         -0.138152
2   2         -0.210882
2   3          0.880040
2   4         -0.314704
2   5          0.308067
2   6         -0.279493
2   7          0.617040

Layer (3)
Weights:
3   0     0              0.105712
3   0     1             -0.596065
3   0     2              0.084832
3   1     0             -0.259718
3   1     1             -0.259551
3   1     2              0.154508
3   2     0             -0.237477
3   2     1             -0.311545
3   2     2             -0.183534
3   3     0             -0.056099
3   3     1              0.383610
3   3     2              0.715173
3   4     0              0.496614
3   4     1              0.257080
3   4     2             -0.046464
3   5     0             -0.452341
3   5     1             -0.190234
3   5     2              0.007440
3   6     0              0.192654
3   6     1             -0.332811
3   6     2              0.057849
3   7     0             -0.186799
3   7     1              0.566764
3   7     2             -0.158553

Biases:
3   0          0.611448
3   1          0.296125
3   2          0.062705

Activators: [RECTIFIER, RECTIFIER, RECTIFIER, IDENTITY]
Scale values = kex;1500.0,500.0:r2;30.0,5.0:dppmmin;2.0,1.0:r2eff;150.0,0.0:fields;95.0,50.0